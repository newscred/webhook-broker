# This is the default configuration to be used even if none supplied

# Database connection settings
[rdbms]
dialect=sqlite3
connection-url=webhook-broker.sqlite3
# Use config akin to these for connecting to MySQL; note the multiStatements=true in connection param; without it migration will fail
# dialect=mysql
# connection-url=webhook_broker:zxc909zxc@tcp(mysql:3306)/webhook-broker?charset=utf8mb4&collation=utf8mb4_0900_ai_ci&parseTime=true&multiStatements=true
connxn-max-idle-time-seconds=0
connxn-max-lifetime-seconds=0
max-idle-connxns=30
max-open-connxns=100

# HTTP Server settings
[http]
# Listener address must be bindable else it will error out
listener=:8080
read-timeout=240
write-timeout=240

# Log settings
[log]
# default is console logging, signified by passing empty value
filename=
# Enable file logging by uncommenting the following line
# filename=/var/log/webhook-broker.log
max-file-size-in-mb=200
max-backups=3
max-age-in-days=28
compress-backups=true
# Allowed values are debug, info, error, fatal
log-level=debug

# Generic Webhook Broker config such as - Max message queue size, max workers, priority dispatcher on, retrigger base-endpoint
[broker]
max-message-queue-size=10000
max-workers=200
priority-dispatcher-enabled=true
# If retrigger base endpoint is not a absolute URL config initialization will error out
retrigger-base-endpoint=http://localhost:8080
max-retry=5
rational-delay-in-seconds=2
# Expected comma separated list of numbers; in case any value is a non number it will be defaulted to 15
retry-backoff-delays-in-seconds=5,30,60
# Whether to run recovery workers
recovery-workers-enabled=true

# Settings around pruning of messages already sent
[prune]
# Since there can be multiple webhook broker archiving to a single bucket, this is to distinguish which instance
# this archive is coming from. A URL would look like - {remote-export-url or export-path}/{remote-file-prefix}/{export-node-name}/{datetime_of_prune_op}_{rotation_index}.jsonl
export-node-name=
# How many days to wait before the message is pruned if fully delivered
message-retention-days=0
# Whether remote destination is S3 or GCS
remote-export-destination=
# Connection string to the bucket in question
remote-export-url=
# Local file system path to export to
export-path=
# A prefix to add before the file is written 
remote-file-prefix=
# Maximum single file size in megabytes
max-archive-file-size-in-mb=100

# Generic consumer configuration such as - Token Header name, User Agent, Consumer connection timeout
[consumer-connection]
token-header-name=X-Broker-Consumer-Token
user-agent=Webhook Message Broker
connection-timeout-in-seconds=30

# Preemptive Channel, Producer, Consumer setup
[initial-channels]
sample-channel=Sample Channel

[initial-producers]
sample-producer=Sample Producer

[initial-consumers]
# If consumer callback URL is not a absolute URL the consumer will be ignored
sample-consumer=http://sample-endpoint/webhook-receiver

# Support for preemptive token setup for the aboves
[initial-channel-tokens]
sample-channel=sample-channel-token

[initial-producer-tokens]
sample-producer=sample-producer-token

[sample-consumer]
token=sample-consumer-token
# Supports single `channel` key when; channel must be present
channel=sample-channel
